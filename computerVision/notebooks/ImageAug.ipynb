{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQSH2Ke8Hz457HxeFIbRN4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumbokh/csu1111-class/blob/main/computerVision/notebooks/ImageAug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pDSXvwewa-P",
        "outputId": "0cc9170a-12ae-400f-fc0b-0f28fd7d5eef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab\\ Notebooks\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "T40tVEv-wlE2",
        "outputId": "c0e741a1-5d75-4199-e42a-334241000f21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -fs /content/drive/MyDrive/Colab\\ Notebooks /app\n",
        "%ls /app"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT7Yj1Xjw6gX",
        "outputId": "0bb401ae-261d-4607-a1f0-76f50370f25a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;36m/app\u001b[0m@\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /app\n",
        "%ls"
      ],
      "metadata": {
        "id": "EHic1ns3xJNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3l75ktXxQcN",
        "outputId": "f3c76036-3a60-490d-9285-5ca9693698e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-58be7a31-0e82-6d07-bdac-e8a9cd32112c)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Augmentation for Deep Learning with Keras\n",
        "* https://machinelearningmastery.com/image-augmentation-deep-learning-keras/\n",
        "```\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator()\n",
        "datagen.fit(train)\n",
        "X_batch, y_batch = datagen.flow(train, train, batch_size=32)\n",
        "fit_generator(datagen, samples_per_epoch=len(train), epochs=100)\n",
        "```"
      ],
      "metadata": {
        "id": "-4uAu9JxQPwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Point of Comparison for Image Augmentation\n"
      ],
      "metadata": {
        "id": "gcG2-1A7Qwv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot images\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "# load dbata\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# create a grid of 3x3 images\n",
        "fig, ax = plt.subplots(3, 3, sharex=True, sharey=True, figsize=(4,4))\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        ax[i][j].imshow(X_train[i*3+j], cmap=plt.get_cmap(\"gray\"))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZoBwOtufyI7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Standardization"
      ],
      "metadata": {
        "id": "ZPesmOPLRE7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize images across the dataset, mean=0, stdev=1\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][width][height][channels]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "# convert from int to float\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# define data preparation\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# fit parameters from data\n",
        "datagen.fit(X_train)\n",
        "# configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9, shuffle=False):\n",
        "    print(X_batch.min(), X_batch.mean(), X_batch.max())\n",
        "    # create a grid of 3x3 images\n",
        "    fig, ax = plt.subplots(3, 3, sharex=True, sharey=True, figsize=(4,4))\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            ax[i][j].imshow(X_batch[i*3+j], cmap=plt.get_cmap(\"gray\"))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "metadata": {
        "id": "nxo4ndBRP7x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize images across the dataset, every pixel has mean=0, stdev=1\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][width][height][channels]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "# convert from int to float\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# define data preparation\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# fit parameters from data\n",
        "datagen.mean = X_train.mean(axis=0)\n",
        "datagen.std = X_train.std(axis=0)\n",
        "# configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9, shuffle=False):\n",
        "    print(X_batch.min(), X_batch.mean(), X_batch.max())\n",
        "    # create a grid of 3x3 images\n",
        "    fig, ax = plt.subplots(3, 3, sharex=True, sharey=True, figsize=(4,4))\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            ax[i][j].imshow(X_batch[i*3+j], cmap=plt.get_cmap(\"gray\"))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "metadata": {
        "id": "TbvVg1UpQBwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ZCA Whitening\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][width][height][channels]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "# convert from int to float\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# define data preparation\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True, zca_whitening=True)\n",
        "# fit parameters from data\n",
        "X_mean = X_train.mean(axis=0)\n",
        "datagen.fit(X_train - X_mean)\n",
        "# configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(X_train - X_mean, y_train, batch_size=9, shuffle=False):\n",
        "    print(X_batch.min(), X_batch.mean(), X_batch.max())\n",
        "    # create a grid of 3x3 images\n",
        "    fig, ax = plt.subplots(3, 3, sharex=True, sharey=True, figsize=(4,4))\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            ax[i][j].imshow(X_batch[i*3+j].reshape(28,28), cmap=plt.get_cmap(\"gray\"))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "metadata": {
        "id": "QHeLzjcdQGbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Rotations"
      ],
      "metadata": {
        "id": "bV5QsCu8RbGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Rotations\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][width][height][channels]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "# convert from int to float\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# define data preparation\n",
        "datagen = ImageDataGenerator(rotation_range=90)\n",
        "# configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9, shuffle=False):\n",
        "    # create a grid of 3x3 images\n",
        "    fig, ax = plt.subplots(3, 3, sharex=True, sharey=True, figsize=(4,4))\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            ax[i][j].imshow(X_batch[i*3+j].reshape(28,28), cmap=plt.get_cmap(\"gray\"))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "metadata": {
        "id": "ZLeYNX-URbpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Shifts"
      ],
      "metadata": {
        "id": "3XpoDbFLRlsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Shifts\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][width][height][channels]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "# convert from int to float\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# define data preparation\n",
        "shift = 0.2\n",
        "datagen = ImageDataGenerator(width_shift_range=shift, height_shift_range=shift)\n",
        "# configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9, shuffle=False):\n",
        "    # create a grid of 3x3 images\n",
        "    fig, ax = plt.subplots(3, 3, sharex=True, sharey=True, figsize=(4,4))\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            ax[i][j].imshow(X_batch[i*3+j].reshape(28,28), cmap=plt.get_cmap(\"gray\"))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "metadata": {
        "id": "5ZiqhLa9Rm57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Flips"
      ],
      "metadata": {
        "id": "AmbwR58eRrGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Flips\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][width][height][channels]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "# convert from int to float\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# define data preparation\n",
        "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
        "# configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9, shuffle=False):\n",
        "    # create a grid of 3x3 images\n",
        "    fig, ax = plt.subplots(3, 3, sharex=True, sharey=True, figsize=(4,4))\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            ax[i][j].imshow(X_batch[i*3+j].reshape(28,28), cmap=plt.get_cmap(\"gray\"))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "metadata": {
        "id": "_rPrTUFzRuk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Augmented Images to File"
      ],
      "metadata": {
        "id": "hEim66EWRzGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save augmented images to file\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][width][height][channels]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "# convert from int to float\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# define data preparation\n",
        "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
        "# configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9, shuffle=False,\n",
        "                                     save_to_dir='images', save_prefix='aug', save_format='png'):\n",
        "    # create a grid of 3x3 images\n",
        "    fig, ax = plt.subplots(3, 3, sharex=True, sharey=True, figsize=(4,4))\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            ax[i][j].imshow(X_batch[i*3+j].reshape(28,28), cmap=plt.get_cmap(\"gray\"))\n",
        "    # show the plot\n",
        "    plt.show()\n",
        "    break"
      ],
      "metadata": {
        "id": "uK2mpe5zR23_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tips for Augmenting Image Data with Keras\n",
        "```\n",
        "Image data is unique in that you can review the data and transformed copies of the data and quickly get an idea of how the model may perceive it.\n",
        "\n",
        "Below are some tips for getting the most from image data preparation and augmentation for deep learning.\n",
        "\n",
        "Review Dataset. Take some time to review your dataset in great detail. Look at the images. Take note of image preparation and augmentations that might benefit the training process of your model, such as the need to handle different shifts, rotations, or flips of objects in the scene.\n",
        "Review Augmentations. Review sample images after the augmentation has been performed. It is one thing to intellectually know what image transforms you are using; it is a very different thing to look at examples. Review images both with individual augmentations you are using as well as the full set of augmentations you plan to use. You may see ways to simplify or further enhance your model training process.\n",
        "Evaluate a Suite of Transforms. Try more than one image data preparation and augmentation scheme. Often you can be surprised by the results of a data preparation scheme you did not think would be beneficial.\n",
        "```"
      ],
      "metadata": {
        "id": "3_DlKRxlR_5S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7juELlRBSMN_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}